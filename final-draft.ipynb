{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_curve, auc, plot_roc_curve, classification_report\n",
    "from math import exp\n",
    "from IPython.display import display_html, display,HTML\n",
    "import random\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data from url web address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = 'https://raw.githubusercontent.com/efratkohen/Big_five/master/big_five_scores.csv'\n",
    "df=pd.read_csv(csv_url, index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_14345114308967114265() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_14345114308967114265()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add show/hide option for the jupyter notebook. press the show/hide button after running this cell.\n",
    "def hide_toggle(text='Toggle', for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = text + ' show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307313 entries, 1 to 334161\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   country                  307141 non-null  object \n",
      " 1   age                      307313 non-null  int64  \n",
      " 2   sex                      307313 non-null  int64  \n",
      " 3   agreeable_score          307313 non-null  float64\n",
      " 4   extraversion_score       307313 non-null  float64\n",
      " 5   openness_score           307313 non-null  float64\n",
      " 6   conscientiousness_score  307313 non-null  float64\n",
      " 7   neuroticism_score        307313 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 21.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of rows containig nan values is 0.06% \n"
     ]
    }
   ],
   "source": [
    "NAN_rows = df.shape[0] - df.dropna().shape[0]\n",
    "NAN_percent = NAN_rows/df.shape[0]\n",
    "print(f\"The amount of rows containig nan values is {(NAN_percent * 100):.2f}% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all nan values after review that there are less than 0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>agreeable_score</th>\n",
       "      <th>extraversion_score</th>\n",
       "      <th>openness_score</th>\n",
       "      <th>conscientiousness_score</th>\n",
       "      <th>neuroticism_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307,141.00</td>\n",
       "      <td>307,141.00</td>\n",
       "      <td>307,141.00</td>\n",
       "      <td>307,141.00</td>\n",
       "      <td>307,141.00</td>\n",
       "      <td>307,141.00</td>\n",
       "      <td>307,141.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.19</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age        sex  agreeable_score  extraversion_score  \\\n",
       "count 307,141.00 307,141.00       307,141.00          307,141.00   \n",
       "mean       25.19       1.60             0.70                0.67   \n",
       "std        10.00       0.49             0.09                0.11   \n",
       "min        10.00       1.00             0.20                0.20   \n",
       "25%        18.00       1.00             0.64                0.60   \n",
       "50%        22.00       2.00             0.70                0.68   \n",
       "75%        29.00       2.00             0.76                0.75   \n",
       "max        99.00       2.00             1.00                0.99   \n",
       "\n",
       "       openness_score  conscientiousness_score  neuroticism_score  \n",
       "count      307,141.00               307,141.00         307,141.00  \n",
       "mean             0.73                     0.70               0.57  \n",
       "std              0.09                     0.11               0.13  \n",
       "min              0.25                     0.21               0.20  \n",
       "25%              0.67                     0.63               0.49  \n",
       "50%              0.74                     0.71               0.57  \n",
       "75%              0.80                     0.78               0.66  \n",
       "max              1.00                     1.00               1.00  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data balance between female and male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data containes 60.26% female's surveys and 39.74% male's surveys\n"
     ]
    }
   ],
   "source": [
    "gender_count = data['sex'].value_counts(normalize=True)\n",
    "print(f\"The data containes {(gender_count.iloc[0]*100):.2f}% female's surveys and {(gender_count.iloc[1]*100):.2f}% male's surveys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot visualization with femal/male color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(data, hue='sex')\n",
    "new_labels = ['Male', 'Female']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "_=g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot visualization for the five personality traits by sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_traits = ['agreeable_score', 'extraversion_score', 'openness_score', 'conscientiousness_score','neuroticism_score']\n",
    "data1 = pd.melt(data, id_vars=['sex'], value_vars=personality_traits)\n",
    "data1.loc[(data1.sex == 1),'sex'] = 'Male'\n",
    "data1.loc[(data1.sex == 2),'sex'] = 'Female'\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "m = sns.boxplot(ax=ax, data=data1, x=\"variable\", y=\"value\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot visualization for age by sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_melt = pd.melt(data, id_vars=['sex'], value_vars=['age'])\n",
    "data_age_melt.loc[(data_age_melt.sex == 1),'sex'] = 'Male'\n",
    "data_age_melt.loc[(data_age_melt.sex == 2),'sex'] = 'Female'\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "m = sns.boxplot(ax=ax, data=data_age_melt, x=\"variable\", y=\"value\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calaulation for the amount of countries in the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The data containes {len(data.country.unique())} different countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many observations there are for each country in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = data.groupby(['country'])['age'].count().sort_values(ascending=True)\n",
    "_=country.plot(kind='barh', figsize=(20,50))\n",
    "_=plt.xlabel(\"Number of observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions from the data exploratory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gender: The data is not balanced, there are more female observations than male.\n",
    "2. Age: Most of the surveys are of young people in their twenties. It's not representative for the world's population.\n",
    "3. Countries: USA has the majority of the observations (69%) and only 11 more countries has more than 0.5% of the observations.\n",
    "4. Personality traits: All the personality distribution of female are a bit higher than male, espesially neuroticism and agreeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to the exploratory data analysis we decided to:\n",
    "1. Balance the data by gender\n",
    "2. With one-hot encoding we gave a specific feature for only countries with significant amount of surveys (more than 0.5%) and all the other countries gather together to one feature 'other'.\n",
    "3. Normalize the data\n",
    "4. Add new features of multiplication of any two personality scores.\n",
    "5. We tried to use PCA for dimensionality reduction, due to simalarity of personality traits, but decided not to use it has the results didn't show beneficial output. \n",
    "6. We tried to use K-means in order to see if there is a 'cultural' diversety (by countries regions), but decided not to use it has the results didn't show beneficial output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to run the models on three different 'data' in order to understand the preprocessing influence on the results:\n",
    "1. raw_data: the original data without NaN and with significant countries one-hot encoding and normalization.\n",
    "2. balanced_data: downsampled femal's observations from raw_data to match population's gender distribution.\n",
    "3. balanced_interacted_data: balanced_data with new features of multiplication of any two personality scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narrow countries to only ones with more than 0.5% percent of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lenght = len(data)\n",
    "significant_percent = 0.005\n",
    "significant_observations = significant_percent * data_lenght\n",
    "country[country > significant_observations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = country[country > significant_observations].index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Dataframes of chosen country binary variables and join with data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.get_dummies(data['country'][data['country'].isin(country_list)])\n",
    "data_country = pd.concat([data, countries] ,axis=1)\n",
    "data_country.insert(20, 'Other', np.where(np.isnan(data_country['UK'].values), 1, 0)) #add 'other' country column\n",
    "raw_data = data_country.fillna(0).drop(['country'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "names = raw_data.columns\n",
    "d = scaler.fit_transform(raw_data)\n",
    "scaled_raw_data = pd.DataFrame(d, index=raw_data.index, columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spliting the data to train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'sex'\n",
    "scaled_raw_train, scaled_raw_test = train_test_split(scaled_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_raw_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_raw_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "World's population is 50.5% male and 49.5% females (https://countrymeters.info/en/World). The original data containes 60.26% female's surveys and 39.74% male's surveys. Therefore we undersample femal's observations from our train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class = scaled_raw_train['sex'].value_counts()[0]\n",
    "print(f\"The scaled_raw_train data containes {(scaled_raw_train['sex'].value_counts()[1])} female's surveys and {(scaled_raw_train['sex'].value_counts()[0])} male's surveys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the Dataset.\n",
    "shuffled_df = scaled_raw_train.sample(frac=1,random_state=4)\n",
    "\n",
    "# Put all the male class in a separate dataset.\n",
    "male_df = shuffled_df.loc[shuffled_df['sex'] == 0] #0= male, 1= female\n",
    "\n",
    "#Randomly select minority_class number observations from the female (majority class)\n",
    "female_df = shuffled_df.loc[shuffled_df['sex'] == 1].sample(n=minority_class,random_state=42)\n",
    "\n",
    "# Concatenate both dataframes again\n",
    "balanced_train = pd.concat([male_df, female_df])\n",
    "\n",
    "#plot the dataset after undersampling\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot('sex', data=balanced_train)\n",
    "plt.title('Balanced Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balanced_interacted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new features of multiplication of any two personality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Personality_Traits_list = ['agreeable_score', 'extraversion_score', 'openness_score', 'conscientiousness_score', 'neuroticism_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run on Personality_Traits and multiply scores of any two pairs\n",
    "def feature_interactions(data: pd.DataFrame, Personality_Traits_list: list):\n",
    "    \"\"\"\n",
    "    multiply any two columns of Personality_Traits and save the result in a new column.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    data: pd.DataFrame\n",
    "    Personality_Traits_list: list\n",
    "        Features's list of Personality_Traits\n",
    "    \n",
    "    return\n",
    "    \n",
    "    interacted_data :pd.DataFrame\n",
    "    \"\"\"\n",
    "    interacted_data = data.copy()\n",
    "    i = 0\n",
    "    j = i+1\n",
    "    while i < (len(Personality_Traits_list)-1):\n",
    "        # new feature name\n",
    "        new_feature = Personality_Traits_list[i] + '*' + Personality_Traits_list[j]\n",
    "        # multiply personality score of index i with personality score of index j=i+1\n",
    "        interacted_data[new_feature] = interacted_data[Personality_Traits_list[i]] * interacted_data[Personality_Traits_list[j]] \n",
    "        j = j+1\n",
    "        # check for end of list\n",
    "        if j == len(Personality_Traits_list):\n",
    "            i= i+1\n",
    "            j=i+1\n",
    "    #normalize the data:\n",
    "    names = raw_data.columns\n",
    "    d = scaler.fit_transform(interacted_data)\n",
    "    interacted_data = pd.DataFrame(d, index=interacted_data.index, columns=names)\n",
    "    \n",
    "    return interacted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_interacted_train = feature_interactions(balanced_train, Personality_Traits_list)\n",
    "interacted_test = feature_interactions(scaled_raw_test, Personality_Traits_list) #the test data was not balanced, we only add the interaction columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_interacted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interacted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preprocessing we also tried:\n",
    "K-Mean, outliers handeling and PCA\n",
    "but eventually decided not to use them, because it didn't help the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "def pca_plot(data: pd.DataFrame, features: list, color_col: str =\"sex\"):\n",
    "    \"\"\"\n",
    "    Plots the PCA as desired. \n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    data: pd.DataFrame\n",
    "    features: list\n",
    "        Features's list that we would like to reduce dimension\n",
    "    ax_i: plt.axes\n",
    "    color_col: str\n",
    "        name of column to color the dots by.\n",
    "    \"\"\"\n",
    "    x_only = data_country[features]\n",
    "\n",
    "    pca_model = make_pipeline(StandardScaler(), PCA(n_components=2))\n",
    "    pca_model.fit(x_only)\n",
    "\n",
    "    X_2D = pca_model.transform(x_only)\n",
    "    pca_dict = dict(PCA1=X_2D[:, 0], PCA2=X_2D[:, 1])\n",
    "    pca_results = pd.DataFrame(pca_dict)\n",
    "\n",
    "    color_series = data.loc[:, (color_col)].reset_index(drop=True)\n",
    "\n",
    "    pca_results[\"color\"] = color_series\n",
    "\n",
    "    g = sns.scatterplot(data=pca_results, x=\"PCA1\", y=\"PCA2\", hue=\"color\")\n",
    "    g.legend_.remove()\n",
    "    g.set(title=f\"PCA of {features} colored by {color_col}\")\n",
    "_=pca_plot(scaled_raw_data, Personality_Traits_list)\n",
    "hide_toggle('PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans\n",
    "Kmeans = KMeans(n_clusters=3)\n",
    "Kmeans.fit(scaled_raw_data[Personality_Traits_list])\n",
    "y_km = Kmeans.fit_predict(scaled_raw_data[Personality_Traits_list])\n",
    "new_series = pd.Series(y_km, index=scaled_raw_data.index, name='cluster')\n",
    "scaled_raw_data_Kmeans = pd.concat([scaled_raw_data, new_series] ,axis=1)\n",
    "#Evaluation of the cluster result \n",
    "scaled_raw_data_Kmeans.groupby(by=[\"cluster\", \"sex\"]).median()\n",
    "scaled_raw_data_Kmeans.groupby(by=[\"cluster\", \"sex\"]).count()\n",
    "scaled_raw_data_Kmeans.groupby(by=[\"cluster\", \"sex\"]).mean()\n",
    "scaled_raw_data_Kmeans.groupby(by=[\"cluster\", \"sex\"]).sum()\n",
    "hide_toggle('Kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the three trained data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = [scaled_raw_train, balanced_train, balanced_interacted_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried few models (Logistic regression, Linear regression, Decision trees, Gradient Boosting).\n",
    "the best results were given by Logistic regression and  Gradient Boosting, we will show them here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'sex'\n",
    "\n",
    "models_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "y_predicted_list = []\n",
    "X_train_list = []\n",
    "datasets_names = ['scaled_raw', 'balanced', 'balanced_interacted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Logistic regression model on the three datas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_data in train_datasets:\n",
    "    \n",
    "    #split train and test to X and y:\n",
    "    X_train = train_data.drop(columns=[target_name])\n",
    "    y_train = train_data[target_name].copy() \n",
    "    X_train_list.append(X_train)\n",
    "    #fit the model according to train data\n",
    "    Lreg = LogisticRegression(max_iter=100000).fit(X_train, y_train)\n",
    "    #save model to model list\n",
    "    models_list.append(Lreg)\n",
    "    \n",
    "    #different kind of test data because of the added columns\n",
    "    if (train_data.equals(balanced_interacted_train)):\n",
    "\n",
    "        X_test = interacted_test.drop(columns=[target_name])\n",
    "        y_test = interacted_test[target_name].copy()   \n",
    "    else:\n",
    "        #first two options\n",
    "        X_test = scaled_raw_test.drop(columns=[target_name])\n",
    "        y_test = scaled_raw_test[target_name].copy()   \n",
    "        \n",
    "    X_test_list.append(X_test)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    \n",
    "    #predict \n",
    "    y_predicted = Lreg.predict(X_test)\n",
    "    y_predicted_list.append(y_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results of Report, ROC curve and confusion_matrix for the three options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Male', 'Female']\n",
    "\n",
    "\n",
    "# Creat plots for comparison\n",
    "fig_roc, ax_roc = plt.subplots(nrows=1, ncols=3, figsize=(30,13 ))\n",
    "fig_cm, ax_cm = plt.subplots(nrows=1, ncols=3, figsize=(25, 10))\n",
    "\n",
    "\n",
    "for i in range(len(train_datasets)):\n",
    "    #roc curve\n",
    "    _ = plot_roc_curve(models_list[i], X_test_list[i], y_test_list[i],\n",
    "                       ax=ax_roc[i])\n",
    "    \n",
    "\n",
    "for i in range(len(train_datasets)):\n",
    "    #confusion matrix\n",
    "    disp = plot_confusion_matrix(models_list[i],\n",
    "                             X_test_list[i],\n",
    "                             y_test_list[i],\n",
    "                             display_labels=['Male', 'Female'],\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=\"true\", ax = ax_cm[i], colorbar=True)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "report_list = []\n",
    "# pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "\n",
    "for i in range(len(train_datasets)):\n",
    "    #classification report\n",
    "    report = classification_report(y_test_list[i], y_predicted_list[i], target_names=target_names, output_dict=True, digits=2)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_list.append(report_df)\n",
    "\n",
    "\n",
    "df1_styler = report_list[0].style.set_table_attributes(\"style='display:inline'\").set_precision(2).set_properties(**{\n",
    "#     'background-color': 'grey',\n",
    "    'font-size': '8pt',\n",
    "}).set_caption(datasets_names[0])\n",
    "df2_styler = report_list[1].style.set_table_attributes(\"style='display:inline'\").set_precision(2).set_properties(**{\n",
    "#     'background-color': 'grey',\n",
    "    'font-size': '8pt',\n",
    "}).set_caption(datasets_names[1])\n",
    "df3_styler = report_list[2].style.set_table_attributes(\"style='display:inline'\").set_precision(2).set_properties(**{\n",
    "#     'background-color': 'grey',\n",
    "    'font-size': '8pt',\n",
    "}).set_caption(datasets_names[2])\n",
    "\n",
    "\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_()+df3_styler._repr_html_(), raw=True)\n",
    "    \n",
    "    \n",
    "hide_toggle('Plots')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Gradiant Boosting model on the three datas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list_GB = []\n",
    "y_predicted_list_GB = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_data in train_datasets:\n",
    "    \n",
    "    #split train and test to X and y:\n",
    "    X_train = train_data.drop(columns=[target_name])\n",
    "    y_train = train_data[target_name].copy()   \n",
    "    #fit the model according to train data\n",
    "    gradient_boosting  = GradientBoostingClassifier(random_state =0).fit(X_train, y_train)\n",
    "    #save model to model list\n",
    "    models_list_GB.append(gradient_boosting)\n",
    "    \n",
    "    #different kind of test data because of the added columns\n",
    "    if (train_data.equals(balanced_interacted_train)):\n",
    "\n",
    "        X_test = interacted_test.drop(columns=[target_name])\n",
    "        y_test = interacted_test[target_name].copy()   \n",
    "    else:\n",
    "        #first two options\n",
    "        X_test = scaled_raw_test.drop(columns=[target_name])\n",
    "        y_test = scaled_raw_test[target_name].copy()   \n",
    "        \n",
    "    #predict \n",
    "    y_predicted = gradient_boosting.predict(X_test)\n",
    "    y_predicted_list_GB.append(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results of Report, ROC curve and confusion_matrix for the three options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_datasets)):\n",
    "    print(\"Plots for \", datasets_names[i])\n",
    "    _ = plot_roc_curve(models_list[i], X_test_list[i], y_test_list[i])\n",
    "    report = classification_report(y_test_list[i], y_predicted_list[i], target_names=target_names)\n",
    "    print(report)\n",
    "    disp = plot_confusion_matrix(models_list[i],\n",
    "                                 X_test_list[i],\n",
    "                                 y_test_list[i],\n",
    "                                 display_labels=['Male', 'Female'],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=\"true\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that balancing the data had the most significant influance on the results - it improved the male prediction.\n",
    "If the female's recall is more important than the man's recall - the raw data will be preferable.\n",
    "The interacted features didn't improve the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model - explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calaulate Logistic Regression explainability by odds ratio equation:\n",
    "$\\frac{Odds_{X_{j+1}}}{Odds_{X_{j}}} = e^{β_{j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainability_Logistic_Regression (coef: np.array, delta: float):\n",
    "    value = []\n",
    "    for i in range(coef.shape[1]):\n",
    "        value.append(exp(Lreg.coef_[0][i]*delta))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot explainability bar graph for each data option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_list)):\n",
    "    coef = models_list[i].coef_\n",
    "    Explainability = explainability_Logistic_Regression(coef, 0.3) #delta is positive - probability for femal\n",
    "    Explainability_df = pd.Series(np.array(Explainability),  index=X_test_list[i].columns.to_list(), name='Explainability')\n",
    "    _=Explainability_df.nlargest(20).sort_values().plot(kind='barh')\n",
    "    plt.title(datasets_names[i])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting model - Shap explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calaulate and plot Gradient Boosting explainability by shap for each data option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_list)):\n",
    "    print(f\"                                    {datasets_names[i]}\")\n",
    "    explainer = shap.Explainer(models_list_GB[i])\n",
    "    shap_values = explainer(X_train_list[i])\n",
    "    shap.plots.bar(shap_values)\n",
    "    shap.plots.beeswarm(shap_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
